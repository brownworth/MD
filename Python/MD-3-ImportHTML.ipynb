{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pandas and Numpy with Data\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll need to import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of how to read a table from Wikipedia, harvest some data, and change it around so that it reads well for NumPy and Pandas.\n",
    "\n",
    "This first entry describes the `.read_html()` function from the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_html?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = pd.read_html(r'https://en.wikipedia.org/wiki/Parks_and_Recreation_%28season_1%29',header=0)\n",
    "episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we've passed two arguments to the pd.read_html() method. First, we're passing the URL. Pandas will use other installed libraries to connect to this URL and begin extracting the tables as a list. Notice the '[' at the beginning, and the ']' all the way at the end? That should be an indication that it is a list.  Of course you could always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is a list, it can be sliced. We just need to figure out which slice we want. Is it the first one? (remember, Python is zero-indexed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we could do some things with this, this table isn't the full data we're looking to process. For this page, we're looking at the second table, or `episodes[1]`. We'll go ahead and assign that to a variable we're calling 'season'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "season = episodes[1]\n",
    "season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here that there are a bunch of cells with 'NaN' in them. We talked about 'Not a Number' before, and again NumPy is saying that it couldn't find or interpret data here. We could use some Pandas functions to deal with these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "season.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .dropna() method effectively drops any rows where there are one or more NaN entries. Unfortunately, while the rows were mostly NaN, there were some cells with data in them. By default, .dropna() has the argument **how='any'**. Meaning, if a row contains one or more NaN, then .dropna() will drop it. Instead, we can use .dropna(how='all'). This will only drop rows where all cells are NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "season.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't show anything here, as we don't have any rows that are completely filled with NaN. But, we can use .fillna() to automatically change that value to something else that may be relevant to your data collection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season.fillna(-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".fillna() has multiple methods, like forward fill, backward fill, interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# season.fillna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while .fillna() is useful, the information contained in surrounding cells isn't that useful to us. It appears that in the case of this table, the first row (row 0) and each alternating row has information about the episode, and the second row (row 1) and each alternating row has the episode description of the previous episode. How do we deal with that? Slices, of course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season[1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These slices will get us the descriptions alone, but we have a bunch of extra cells that are NaN, and irrelevant. Let's drop those using the indexers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season[1::2].iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas really wants to maintain the indices, which is usually really helpful - it helps prevent data mismatches down the road. But, what if we really want to ignore the index? We can reset it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season[1::2].iloc[:,0].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have created a new index, but Pandas (trying to save us from ourselves) has kept the index values from before, but in a separate Series within the new DataFrame. All we have to do now is drop it. While we're at it, let's go ahead and create an episode description variable and set it equal to this new series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_desc = season[1::2].iloc[:,0].reset_index().drop('index',axis=1)\n",
    "episode_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column name (No. Overall) doesn't make any sense, so we'll use the `.rename()` method to rename the columns using a dictionary with a single key-value pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "episode_desc = episode_desc.rename(columns = {'No.overall':'Description'})\n",
    "episode_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the other cells in the season dataframe, we want to start at the first row (row 0) and alternate getting all of the ones with the data. Since the procedure will be almost exactly the same as before, we'll skip ahead to the final part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "episode_data = season[0::2].reset_index().drop('index',axis=1)\n",
    "episode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of data and a list of descriptions. By wonderful coincidence (not really), they both have the same number of cells. Let's check to be certain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aside: programming languages are funny about the equals sign '='. A lot of times, we want to see if something is equal to something else. Python assumes that a single equals means that you are **making a thing equal to some other thing**.\n",
    "\n",
    "If you want to check to see if two entities *are equal* then you will use the double equal '=='\n",
    "\n",
    "single = 'is'\n",
    "\n",
    "`age = 5`\n",
    "\n",
    "age _is_ 5\n",
    "\n",
    "double == 'is it'\n",
    "\n",
    "`age == 5`\n",
    "\n",
    "age, _is it_ 5?\n",
    "\n",
    "this is a largely semantic discussion, but you would be surprised how often it causes problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(episode_data) == len(episode_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's concatenate the data DataFrame, and the description Series. Remember to specify axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_list = pd.concat([episode_data,episode_desc],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the column heads just to be certain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_list.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the index to one of the unique Series in the DataFrame. 'No. Overall' makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "episode_list = episode_list.set_index('No.overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of space, the preview here doesn't show all the information, but you can definitely check the contents by using the `.values` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "episode_list['Description'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexers can be used like slices. They have the brackets and colons, but they can also be used in conjunction with commas to indicate two dimensions. In the first example, we use our knowledge of slices on a DataFrame to separate content out in two different ways. We're also using the NumPy `.all()` method to verify that the two sections are equivalent. We can also check the number of entries by using the `.len()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.all(season[1::2].iloc[:,0] == season.iloc[1::2,0])\n",
    "print len(season[1::2].iloc[:,0])\n",
    "print len(season.iloc[1::2,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful when mixing integers with strings for `.loc[]` and `.iloc[]`. Since they both return dataframes (try `type()`) you can always nest the functions if needed. Also, if you need non-contiguous ranges, you can use tuples. We haven't talked much about tuples, but they're basically lists that are _immutable_ to a degree. We won't go too far down this road. Basically, if it looks like a list, but it's surrounded by parentheses, it's a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print type(episode_list)\n",
    "print type(episode_list.iloc[2:4,1:5])\n",
    "print type(episode_list.iloc[2:5].loc[:,('Title','Written by')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode_list.iloc[2:4,1:5]\n",
    "# episode_list.iloc[2:5].loc[:,('Title','Written by')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, all of these are functionally equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# .loc uses strings to locate cells\n",
    "episode_list.loc[:,'Title']\n",
    "\n",
    "# .iloc uses integers to locate cells\n",
    "episode_list.iloc[:,1] \n",
    "\n",
    "# .ix uses strings first, but can use integers if none are available.\n",
    "# It's deprecated, so don't expect it to be here long.\n",
    "#episode_list.ix[:,'Title']\n",
    "\n",
    "#episode_list.ix[:,1]\n",
    "\n",
    "# alternatively, you can refer to the specific column head\n",
    "episode_list['Title']\n",
    "\n",
    "# or use dot notation (if there are no spaces in the column head).\n",
    "episode_list.Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the viewer numbers, they are formatted like this:\n",
    "\n",
    "`4.70[19]`\n",
    "\n",
    "Unfortunately, Pandas doesn't know what to do with this; the format isn't anything it recognizes. So, we're going to temporarily convert it to a string (using the `.str` accessor), and use some string methods on it. Specifically, we'll use the `.split()` method again. This time, however, there isn't a space to _split_ on. As we mentioned before, the `.split()` method allows you to split on a specified character - we'll use the open bracket, as it separates the number from the footnote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_list.iloc[:,5].str.split('[')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells are each split into two values. The numbers before the '[', and everything else. We only care about the stuff in the front, so we'll grab it with (you guessed it) a slice. While we're at it, we're going to go ahead and convert everything to a float, so we can have a number with a decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_list.iloc[:,5] = episode_list.iloc[:,5].str.split('[').str[0].astype('Float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, since it is a number (specifically, a float) we can do math operations on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_list.iloc[:,5].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to use the .apply() method to apply a function to a column. We're going to convert the 'Original air date' column to a DateTime object. Pandas will try to see if there are ways to interpret the information in these cells as dates. First, let's look at the `pd.to_datetime` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_datetime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_list['Original air date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information, `May 14, 2009`, thankfully, is in a format that Pandas can convert with `pd.to_datetime`.\n",
    "\n",
    "*we'll be coming back here later...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_list['Original air date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do some graphing!\n",
    "\n",
    "First, we'll tell jupyter that we want to do the graphs inline, and then we'll import another library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphing can be as simple as using the `.plot()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "episode_list.iloc[:,5:7].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to get really fancy? PyPlot has some really excellent features. We can append this stuff to the default figure 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print type(episode_list.iloc[:,1])\n",
    "print type(episode_list.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.xticks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_titles = episode_list.iloc[:,1].values\n",
    "episode_viewers = episode_list.iloc[:,5].values\n",
    "\n",
    "index = np.arange(len(episode_list))\n",
    "\n",
    "plt.figure(num=None, figsize=(16, 8), facecolor='w', edgecolor='k')\n",
    "plt.xlabel('Episode Titles')\n",
    "plt.title('Parks & Recreation Viewer Stats')\n",
    "plt.xticks(index,episode_titles,rotation=90)\n",
    "plt.ylabel('Viewers (in millions)')\n",
    "plt.plot(index, episode_viewers,'b',label='Viewers')\n",
    "plt.plot(pd.Series(episode_viewers).rolling(window=3).mean(),'r',label='Rolling Mean')\n",
    "plt.grid()\n",
    "\n",
    "plt.legend(); # the semicolon here just removes the command output."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
